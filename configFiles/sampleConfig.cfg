[BERT]
bert_path = bert-base-uncased
bert_dim = 768
trainable_layers = encoder.layer.11.attention.self.query.weight,encoder.layer.11.attention.self.query.bias,encoder.layer.11.attention.self.key.weight,encoder.layer.11.attention.self.key.bias,encoder.layer.11.attention.self.value.weight,encoder.layer.11.attention.self.value.bias,encoder.layer.11.attention.output.dense.weight,encoder.layer.11.attention.output.dense.bias,encoder.layer.11.intermediate.dense.weight,encoder.layer.11.intermediate.dense.bias,encoder.layer.11.output.dense.weight,encoder.layer.11.output.dense.bias

[MODEL]
hidden_dim = 300
z_dim = 50
ntopics = 50
class_topic_loss_lambda = 1
classification_loss_lambda = 1
banlance_loss = yes

[TARGET]
labels = PubAuthAction,CommSpread,GenMedAdv,PromActs,Consp,VirTrans,VirOrgn,PubPrep,Vacc,None 
